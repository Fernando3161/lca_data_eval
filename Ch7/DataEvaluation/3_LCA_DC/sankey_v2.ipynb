{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first need to construct the data\n",
    "\n",
    "import os\n",
    "import sys\n",
    "parent = os.path.realpath(os.path.join(os.path.abspath(''), os.pardir))\n",
    "sys.path.append(parent)\n",
    "\n",
    "import numpy as np\n",
    "from databases.sql_connect import create_connection\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as pex\n",
    "import holoviews as hv\n",
    "from holoviews import dim\n",
    "from bokeh.io import export_png\n",
    "import floweaver\n",
    "from floweaver import *\n",
    "#from ipysankeywidget import SankeyWidget\n",
    "\n",
    "category = \"GPR-Minerals- Total\"\n",
    "category = \"CED - total\"\n",
    "category = \"EDIP-Gold\"\n",
    "category = \"GPR-Minerals- Total\"\n",
    "category = \"ADP-Minerals- Total\"\n",
    "category = \"7122:Gold\"\n",
    "category = \"CML-climate change (GWP 100a)\"\n",
    "category = \"GPR-Minerals- Total\"\n",
    "category = \"CML-climate change (GWP 100a)\"\n",
    "\n",
    "conn = None\n",
    "sns.set_theme()\n",
    "sns.set(context=\"paper\", style=\"darkgrid\", font=\"Times New Roman\")\n",
    "cm = 1/2.54\n",
    "DB_CORR = os.path.join(parent,\"databases\", \"TEMPRO_DB230416_Corr.db\")\n",
    "assert(os.path.exists(DB_CORR))\n",
    "FONTSIZE = 8\n",
    "\n",
    "\n",
    "conn = create_connection(DB_CORR)\n",
    "\n",
    "cats ={\n",
    "    \"CML-climate change (GWP 100a)\": \"Green House Emissions\",\n",
    "    \"CED - total\": \"Primary Energy\",\n",
    "    \"ADP-Minerals- Total\": \"Mineral Depletion\", \n",
    "    \"EI-Minerals- Total\": \"Economic Importance\",\n",
    "    \"GPR-Minerals- Total\":\"Geo-Politic Supply Risk\", \n",
    "    \"EDIP-Gold\": \"Gold -Resource\",\n",
    "    \"7122:Gold\": \"Gold Content\",\n",
    "    \"7103:Copper\": \"Copper Content\",\n",
    "    \"EDIP-Copper\": \"Copper -Resource\",\n",
    "    \"7168:Tantalum\": \"Tantalum Content\",\n",
    "    \"ReCiPe Endpoint (E - A) - total (total)\": \"Total Impacts\",\n",
    "}\n",
    "\n",
    "ps = 6001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lca_contributions(ps_list, category, group=6000):\n",
    "    query = f'SELECT * FROM [{group}LCAResults]'\n",
    "    lca = pd.read_sql_query(query, conn)\n",
    "    lca = lca[lca[\"ProductSystemID\"].isin(ps_list)]\n",
    "    lca = lca[lca[\"Category\"] == category]\n",
    "    lca.set_index(\"ProductSystemID\", inplace=True)\n",
    "    #lca.drop(columns=[\"ID\",\"StandardDev\",\"DataQuality\"], inplace=True)\n",
    "    return lca\n",
    "\n",
    "def get_inventory(group):\n",
    "    queryInv = f'SELECT * FROM [{group}Exchanges]'\n",
    "    inv = pd.read_sql_query(queryInv, conn)\n",
    "    inv[\"Contribution\"] = np.nan\n",
    "    return inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for category in cats.keys():\n",
    "#if True:\n",
    "#category=\"CED - total\"# \"EDIP-Gold\"#\"\"\"CED - total\"  #\"GPR-Minerals- Total\" # \"ADP-Minerals- Total\"#\"CED - total\" \n",
    "def get_sankey_data_category(category):\n",
    "    df_subsubcats = pd.read_excel(\n",
    "        \"2000subsubcats.xlsx\", engine=\"openpyxl\", sheet_name=\"Subsubcat\")\n",
    "    df_subsubcats.set_index(\"ID\", inplace=True)\n",
    "\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    # Need Data of the Inventory as well\n",
    "    lca6 = get_lca_contributions([ps],category, group=6000)\n",
    "    inv6 = get_inventory(group=6000)\n",
    "    inv6 = inv6[inv6[\"6000ID\"] == ps]\n",
    "\n",
    "    # then need the data of the level below\n",
    "    list5 = list(set(inv6[inv6[\"6000ID\"] == ps][\"5000Systems\"]))\n",
    "    lca5 = get_lca_contributions(list5, category, group=5000)\n",
    "\n",
    "    # Now multiply the amount * impact to get cnotrigution\n",
    "    for idx in inv6.index:\n",
    "        inv6.at[idx, \"Subsubcat\"] = \"5_\" + \\\n",
    "            df_subsubcats.at[inv6.at[idx, \"5000Systems\"], \"Subsubcat Short\"]\n",
    "        inv6.at[idx, \"Contribution\"] = inv6.at[idx, \"Amount\"] * \\\n",
    "            lca5.at[inv6.at[idx, \"5000Systems\"], \"Result\"]\n",
    "\n",
    "    inv6[\"Subsubcat_to\"] = np.nan\n",
    "    for idx in inv6.index:\n",
    "        inv6.at[idx, \"Subsubcat_to\"] = \"6_\" + \\\n",
    "            df_subsubcats.at[inv6.at[idx, \"6000ID\"], \"Subsubcat Short\"]\n",
    "\n",
    "    sankey6 = {\"source\": inv6[\"Subsubcat\"],\n",
    "                \"target\": inv6[\"Subsubcat_to\"],\n",
    "                \"value\": inv6[\"Contribution\"]}\n",
    "    sankey_data6 = pd.DataFrame.from_dict(sankey6)\n",
    "    \n",
    "    # inv6.to_csv(\"inv6.csv\")\n",
    "\n",
    "\n",
    "    # get the information from 4000 to 5000\n",
    "    lca5 = get_lca_contributions(list5,category, group=5000)\n",
    "    inv5 = get_inventory(group=5000)\n",
    "    inv5 = inv5[inv5[\"5000ID\"].isin(list5)]\n",
    "    inv5[\"Subsubcat\"] = np.nan\n",
    "\n",
    "    # then need the data of the level below\n",
    "    list4 = list(set(inv5[inv5[\"5000ID\"].isin(list5)][\"4000Devices\"]))\n",
    "    # there are also from 300s and 2000s, more on that later\n",
    "    list4 = [x for x in list4 if x is not None]\n",
    "    lca4 = get_lca_contributions(list4, category, group=4000)\n",
    "\n",
    "    # Now multiply the amount * impact to get cnotrigution\n",
    "    for idx in inv5.index:\n",
    "        try:\n",
    "            ref_amount = df_subsubcats.at[inv5.at[idx,\n",
    "                                                    \"4000Devices\"], \"Ref Unit\"]\n",
    "            inv5.at[idx, \"Contribution\"] = inv5.at[idx, \"Amount\"] * \\\n",
    "                lca4.at[inv5.at[idx, \"4000Devices\"], \"Result\"]/ref_amount\n",
    "            inv5.at[idx, \"Subsubcat\"] = \"4_\" + \\\n",
    "                df_subsubcats.at[inv5.at[idx, \"4000Devices\"], \"Subsubcat Short\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # then need the data of the level below\n",
    "    list3 = list(set(inv5[inv5[\"5000ID\"].isin(list5)][\"3000Pieces\"]))\n",
    "    # there are also from 300s and 2000s, more on that later\n",
    "    list3 = [x for x in list3 if x is not None]\n",
    "    lca3 = get_lca_contributions(list3, category, group=3000)\n",
    "\n",
    "    # Now multiply the amount * impact to get cnotrigution\n",
    "    for idx in inv5.index:\n",
    "        try:\n",
    "            inv5.at[idx, \"Contribution\"] = inv5.at[idx, \"Amount\"] * \\\n",
    "                lca3.at[inv5.at[idx, \"3000Pieces\"], \"Result\"]\n",
    "            inv5.at[idx, \"Subsubcat\"] = \"3_\" + \\\n",
    "                df_subsubcats.at[inv5.at[idx, \"3000Pieces\"], \"Subsubcat Short\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    list2 = list(set(inv5[inv5[\"5000ID\"].isin(list5)][\"2000Parts\"]))\n",
    "    # there are also from 300s and 2000s, more on that later\n",
    "    list2 = [x for x in list2 if x is not None]\n",
    "    lca2 = get_lca_contributions(list2, category, group=2000)\n",
    "\n",
    "    # Now multiply the amount * impact to get cnotrigution\n",
    "    for idx in inv5.index:\n",
    "        try:\n",
    "            inv5.at[idx, \"Contribution\"] = inv5.at[idx, \"Amount\"] * \\\n",
    "                lca2.at[inv5.at[idx, \"2000Parts\"], \"Result\"]\n",
    "            inv5.at[idx, \"Subsubcat\"] = \"2_\" + \\\n",
    "                df_subsubcats.at[inv5.at[idx, \"2000Parts\"], \"Subsubcat Short\"]\n",
    "        except:\n",
    "            pass\n",
    "    inv5[\"Subsubcat_to\"] = np.nan\n",
    "\n",
    "    for idx in inv5.index:\n",
    "        inv5.at[idx, \"Subsubcat_to\"] = \"5_\" + \\\n",
    "            df_subsubcats.at[inv5.at[idx, \"5000ID\"], \"Subsubcat Short\"]\n",
    "\n",
    "    sankey5 = {\"source\": inv5[\"Subsubcat\"],\n",
    "                \"target\": inv5[\"Subsubcat_to\"],\n",
    "                \"value\": inv5[\"Contribution\"]}\n",
    "\n",
    "    sankey_data5 = pd.DataFrame.from_dict(sankey5)\n",
    "    sankey_data5 = sankey_data5.groupby(['source', 'target']).sum().reset_index()\n",
    "\n",
    "\n",
    "    # get sankey data from 3 AND 2 to 4\n",
    "    lca4 = get_lca_contributions(list4, category, group=4000)\n",
    "    inv4 = get_inventory(group=4000)\n",
    "    inv4 = inv4[inv4[\"4000ID\"].isin(list4)]\n",
    "    inv4[\"Subsubcat\"] = np.nan\n",
    "    inv4[\"Subsubcat_out\"] = np.nan\n",
    "    inv4[\"Amount_3000\"] = np.nan\n",
    "    inv4[\"Amount_5000\"] = np.nan\n",
    "    inv4[\"ref_amount\"] = np.nan\n",
    "\n",
    "    # then need the data of the level below\n",
    "    list3 = list(set(inv4[inv4[\"4000ID\"].isin(list4)][\"3000Pieces\"]))\n",
    "    # there are also from 300s and 2000s, more on that later\n",
    "    list3 = [x for x in list3 if x is not None]\n",
    "    lca3 = get_lca_contributions(list3,category, group=3000)\n",
    "\n",
    "    # Now multiply the amount * impact to get cnotrigution\n",
    "    for idx in inv4.index:\n",
    "        demand_5000 = inv5[inv5[\"4000Devices\"] ==\n",
    "                            inv4.at[idx, \"4000ID\"]][\"Amount\"].sum()\n",
    "        inv4.at[idx, \"Amount_5000\"] = demand_5000\n",
    "        ref_amount = df_subsubcats.at[inv4.at[idx, \"4000ID\"], \"Ref Unit\"]\n",
    "        inv4.at[idx, \"ref_amount\"] = ref_amount\n",
    "        amount = inv4.at[idx, \"Amount\"]\n",
    "        try:\n",
    "            inv4.at[idx, \"Contribution\"] = inv4.at[idx, \"Amount\"] * \\\n",
    "                lca3.at[inv4.at[idx, \"3000Pieces\"],\n",
    "                        \"Result\"]/ref_amount*demand_5000\n",
    "            inv4.at[idx, \"Amount_3000\"] = inv4.at[idx,\n",
    "                                                    \"Amount\"]/ref_amount*demand_5000\n",
    "            inv4.at[idx, \"Subsubcat\"] = \"3_\" + \\\n",
    "                df_subsubcats.at[inv4.at[idx, \"3000Pieces\"], \"Subsubcat Short\"]\n",
    "        except:\n",
    "            pass\n",
    "    # Level 2\n",
    "    list2 = list(set(inv4[inv4[\"4000ID\"].isin(list4)][\"2000Parts\"]))\n",
    "    # there are also from 300s and 2000s, more on that later\n",
    "    list2 = [x for x in list2 if x is not None]\n",
    "    lca2 = get_lca_contributions(list2,category, group=2000)\n",
    "\n",
    "    # Now multiply the amount * impact to get cnotrigution\n",
    "    for idx in inv4.index:\n",
    "        demand_5000 = inv5[inv5[\"4000Devices\"] ==\n",
    "                            inv4.at[idx, \"4000ID\"]][\"Amount\"].sum()\n",
    "        ref_amount = df_subsubcats.at[inv4.at[idx, \"4000ID\"], \"Ref Unit\"]\n",
    "        inv4.at[idx, \"ref_amount\"] = ref_amount\n",
    "        inv4.at[idx, \"Amount_5000\"] = demand_5000\n",
    "        try:\n",
    "            inv4.at[idx, \"Contribution\"] = inv4.at[idx, \"Amount\"] * \\\n",
    "                lca2.at[inv4.at[idx, \"2000Parts\"],\n",
    "                        \"Result\"]/ref_amount*demand_5000\n",
    "            name = df_subsubcats.at[inv4.at[idx, \"2000Parts\"], \"Subsubcat Short\"]\n",
    "\n",
    "            if not isinstance(name, str):\n",
    "                inv4.at[idx, \"Subsubcat\"] = \"2_Other\"\n",
    "            else:\n",
    "                inv4.at[idx, \"Subsubcat\"] = \"2_\" + \\\n",
    "                    df_subsubcats.at[inv4.at[idx,\n",
    "                                                \"2000Parts\"], \"Subsubcat Short\"]\n",
    "        except:\n",
    "            pass\n",
    "    #######################################\n",
    "    # there are contributions on the same level, make with care\n",
    "    ####################\n",
    "    # Level 4\n",
    "    list4_a = list(set(inv4[inv4[\"4000ID\"].isin(list4)][\"4000Devices\"]))\n",
    "    list4_a = [x for x in list4_a if x is not None]\n",
    "    lca4_a = get_lca_contributions(list4_a,category, group=4000)\n",
    "\n",
    "    # Now multiply the amount * impact to get cnotrigution\n",
    "    query = f'SELECT * FROM [4000Devices]'\n",
    "    list_ps_4000 = pd.read_sql_query(query, conn)\n",
    "    list_ps_4000.set_index(\"ID\", inplace=True)\n",
    "\n",
    "    for idx in inv4.index:\n",
    "        demand_5000 = inv5[inv5[\"4000Devices\"] ==\n",
    "                            inv4.at[idx, \"4000ID\"]][\"Amount\"].sum()\n",
    "        ref_amount = df_subsubcats.at[inv4.at[idx, \"4000ID\"], \"Ref Unit\"]\n",
    "        inv4.at[idx, \"Amount_5000\"] = demand_5000\n",
    "        inv4.at[idx, \"ref_amount\"] = ref_amount\n",
    "\n",
    "        try:\n",
    "            # dividir para la ref amount de cada 4000\n",
    "            ref_amount_out = list_ps_4000.at[inv4.at[idx,\n",
    "                                                        \"4000Devices\"], \"Amount\"]\n",
    "            inv4.at[idx, \"Contribution\"] = inv4.at[idx, \"Amount\"] * lca4_a.at[inv4.at[idx,\n",
    "                                                                                        \"4000Devices\"], \"Result\"]/ref_amount*demand_5000/ref_amount_out\n",
    "            inv4.at[idx, \"Subsubcat\"] = \"4_\" + \\\n",
    "                df_subsubcats.at[inv4.at[idx, \"4000Devices\"], \"Subsubcat Short\"]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for idx in inv4.index:\n",
    "        inv4.at[idx, \"Subsubcat_out\"] = \"4_\" + \\\n",
    "            df_subsubcats.at[inv4.at[idx, \"4000ID\"], \"Subsubcat Short\"]\n",
    "\n",
    "    inv4 = inv4[inv4[\"Contribution\"].notna()]\n",
    "\n",
    "    inv4_a = deepcopy(inv4)\n",
    "    # get those with 4446\n",
    "    inv4_a_small_it = inv4_a[inv4_a[\"4000Devices\"] == 4446]\n",
    "    table_small_it = inv4_a[inv4_a[\"4000ID\"] == 4446]\n",
    "    ref_amount = 18\n",
    "    idx_4000_to_delete = []\n",
    "    dfs_add = []\n",
    "    for idx in inv4_a_small_it.index:\n",
    "\n",
    "        total_contrib = inv4_a_small_it.at[idx, \"Contribution\"]\n",
    "        amount = inv4_a_small_it.at[idx, \"Amount\"]\n",
    "        amount_5000 = inv4_a_small_it.at[idx, \"Amount_5000\"]\n",
    "        ref_amount__4000 = inv4_a_small_it.at[idx, \"ref_amount\"]\n",
    "        scaling = amount*amount_5000/ref_amount__4000/ref_amount\n",
    "        df_samall_it_new = deepcopy(table_small_it)\n",
    "        idx_4000_to_delete.append(idx)\n",
    "        df_samall_it_new[\"Amount\"] *= scaling\n",
    "        df_samall_it_new[\"Contribution\"] *= scaling\n",
    "        df_samall_it_new[\"Amount_3000\"] *= scaling\n",
    "        # inv4_a_small_it.at[idx, \"Amount_5000\"]/inv4_a_small_it.at[idx, \"ref_amount\"]\n",
    "        df_samall_it_new[\"Amount_5000\"] = 1\n",
    "        df_samall_it_new[\"Subsubcat_out\"] = inv4_a_small_it.at[idx,\n",
    "                                                                \"Subsubcat_out\"]\n",
    "        new_contrib = df_samall_it_new[\"Contribution\"].sum()\n",
    "        dfs_add.append(df_samall_it_new)\n",
    "\n",
    "    inv4_a.drop(idx_4000_to_delete, axis=0, inplace=True)\n",
    "    inv4_b = pd.concat([inv4_a, *dfs_add], ignore_index=True)\n",
    "    inv4_b = inv4_b[inv4_b[\"4000Devices\"] != 4446]\n",
    "    inv4_b.to_csv(\"inv4_b.csv\")\n",
    "\n",
    "    sankey4 = {\"source\": inv4_b[\"Subsubcat\"],\n",
    "                \"target\": inv4_b[\"Subsubcat_out\"],\n",
    "                \"value\": inv4_b[\"Contribution\"]}\n",
    "    sankey_data4 = pd.DataFrame.from_dict(sankey4)\n",
    "    sankey_data4 = sankey_data4.groupby(['source', 'target']).sum().reset_index()\n",
    "\n",
    "    #inv4_b.to_csv(\"inv4_b.csv\")\n",
    "    inv4_reqs3000 = deepcopy(inv4_b)\n",
    "    inv4_reqs3000 = inv4_reqs3000[inv4_reqs3000[\"Amount_3000\"].notna()]\n",
    "    inv4_reqs3000 = inv4_reqs3000[[\"3000Pieces\", \"Amount_3000\"]]\n",
    "    inv4_reqs3000 = inv4_reqs3000.groupby('3000Pieces').sum()\n",
    "\n",
    "    lca3 = get_lca_contributions(list3, category,group=3000)\n",
    "    inv3 = get_inventory(group=3000)\n",
    "    inv3 = inv3[inv3[\"3000ID\"].isin(list3)]\n",
    "    inv3[\"Contribution\"] = np.nan\n",
    "    inv3[\"Subsubcat\"] = np.nan\n",
    "    inv3[\"Subsubcat_out\"] = np.nan\n",
    "    inv3[\"2000_demand\"] = np.nan\n",
    "\n",
    "    # then need the data of the level below\n",
    "    list2 = list(set(inv3[inv3[\"3000ID\"].isin(list3)][\"2000Parts\"]))\n",
    "    list2 = [x for x in list2 if x is not None]\n",
    "    list2 = [x for x in list2 if x != \"\"]\n",
    "\n",
    "    # there are also from 300s and 2000s, more on that later\n",
    "\n",
    "    lca2 = get_lca_contributions(list2, category,group=2000)\n",
    "    # Now multiply the amount * impact to get cnotrigution\n",
    "    for idx in inv3.index:\n",
    "        id_3000 = inv3.at[idx, \"3000ID\"]\n",
    "        demand_3000 = inv4_reqs3000.at[id_3000, \"Amount_3000\"]\n",
    "        piece_id_exchange = inv3.at[idx, \"2000Parts\"]\n",
    "        if not isinstance(piece_id_exchange, str):\n",
    "            if piece_id_exchange in lca2.index:\n",
    "                inv3.at[idx, \"Contribution\"] = inv3.at[idx, \"Amount\"] * \\\n",
    "                    lca2.at[piece_id_exchange, \"Result\"]*demand_3000\n",
    "                inv3.at[idx, \"2000_demand\"] = inv3.at[idx, \"Amount\"]*demand_3000\n",
    "                name = df_subsubcats.at[piece_id_exchange, \"Subsubcat Short\"]\n",
    "\n",
    "                if not isinstance(name, str):\n",
    "                    inv3.at[idx, \"Subsubcat\"] = \"2_Other\"\n",
    "                else:\n",
    "                    inv3.at[idx, \"Subsubcat\"] = \"2_\" + \\\n",
    "                        df_subsubcats.at[inv3.at[idx,\n",
    "                                                    \"2000Parts\"], \"Subsubcat Short\"]\n",
    "\n",
    "    # then need the data of the level below\n",
    "    list3_a = list(set(inv3[inv3[\"3000ID\"].isin(list3)][\"3000Pieces\"]))\n",
    "    list3_a = [x for x in list3_a if x is not None]\n",
    "    lca3_a = get_lca_contributions(list3_a,category, group=3000)\n",
    "\n",
    "    # Now multiply the amount * impact to get cnotrigution\n",
    "    for idx in inv3.index:\n",
    "        id_3000 = inv3.at[idx, \"3000ID\"]\n",
    "        demand_3000 = inv4_reqs3000.at[id_3000, \"Amount_3000\"]\n",
    "\n",
    "        piece_id_exchange = inv3.at[idx, \"3000Pieces\"]\n",
    "        if not isinstance(piece_id_exchange, str):\n",
    "            if piece_id_exchange in lca3_a.index:\n",
    "                inv3.at[idx, \"Contribution\"] = inv3.at[idx, \"Amount\"] * \\\n",
    "                    lca3_a.at[piece_id_exchange, \"Result\"]*demand_3000\n",
    "                inv3.at[idx, \"Subsubcat\"] = \"3_\" + \\\n",
    "                    df_subsubcats.at[piece_id_exchange, \"Subsubcat Short\"]\n",
    "    for idx in inv3.index:\n",
    "        inv3.at[idx, \"Subsubcat_out\"] = \"3_\" + \\\n",
    "            df_subsubcats.at[inv3.at[idx, \"3000ID\"], \"Subsubcat Short\"]\n",
    "\n",
    "        if inv3.at[idx, \"Subsubcat_out\"] == inv3.at[idx, \"Subsubcat\"]:\n",
    "            # inv3.at[idx,\"Subsubcat\"]=\"2_ffff\"+inv3.at[idx,\"Subsubcat\"]\n",
    "            name = inv3.at[idx, \"Subsubcat\"]\n",
    "            inv3.at[idx, \"Subsubcat\"] = \"2_Other\"  # f\"3_3_{name}/{name}\"\n",
    "\n",
    "        if inv3.at[idx, \"Subsubcat\"] == \"3_PCB\" and inv3.at[idx, \"Subsubcat_out\"] == \"3_Small IT\":\n",
    "            print(\"found\")\n",
    "            inv3.at[idx, \"Subsubcat\"] = \"2_PWB\"\n",
    "\n",
    "    sankey3 = {\"source\": inv3[\"Subsubcat\"],\n",
    "                \"target\": inv3[\"Subsubcat_out\"],\n",
    "                \"value\": inv3[\"Contribution\"]}\n",
    "    sankey_data3 = pd.DataFrame.from_dict(sankey3)\n",
    "    sankey_data3 = sankey_data3[sankey_data3[\"source\"].notna()]\n",
    "\n",
    "    sankey_data = pd.concat(\n",
    "        [sankey_data6, sankey_data5, sankey_data4,sankey_data3], ignore_index=True)\n",
    "\n",
    "\n",
    "    for idx in sankey_data.index:\n",
    "        sankey_data.at[idx, \"source\"] = sankey_data.at[idx,\n",
    "                                                     \"source\"].replace(\"4_Energy Supply\", \"4_Energy Supply Dev.\")\n",
    "        sankey_data.at[idx, \"target\"] = sankey_data.at[idx,\n",
    "                                                   \"target\"].replace(\"4_Energy Supply\", \"4_Energy Supply Dev.\")\n",
    "        sankey_data.at[idx, \"source\"] = sankey_data.at[idx,\n",
    "                                                     \"source\"].replace(\"4_Infrastructure\", \"4_Infrastructure Dev\")\n",
    "        sankey_data.at[idx, \"target\"] = sankey_data.at[idx,\n",
    "                                                   \"target\"].replace(\"4_Infrastructure\", \"4_Infrastructure Dev\")\n",
    "        sankey_data.at[idx, \"source\"] = sankey_data.at[idx,\n",
    "                                                     \"source\"].replace(\"4_Climatization\", \"4_Clima. Dev\")\n",
    "        sankey_data.at[idx, \"target\"] = sankey_data.at[idx,\n",
    "                                                   \"target\"].replace(\"4_Climatization\", \"4_Clima. Dev\")\n",
    "\n",
    "    sankey_data = sankey_data.groupby(['source', 'target']).sum().reset_index()\n",
    "\n",
    "    return sankey_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_data_og = get_sankey_data_category(\"CML-climate change (GWP 100a)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb6a5bcae6a49e6bd2388b49eb5cf13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SankeyWidget(groups=[{'id': 'Pieces', 'type': 'process', 'title': 'Pieces', 'nodes': ['Pieces^IC', 'Pieces^PWB…"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "sankey_data= copy.deepcopy(sankey_data_og)\n",
    "total_impact = 0\n",
    "for idx in sankey_data.index:\n",
    "    if sankey_data.at[idx,\"target\"][0:2]==\"6_\":\n",
    "        total_impact+=sankey_data.at[idx,\"value\"]\n",
    "\n",
    "sankey_data[\"value\"] *= (1/total_impact)*100\n",
    "sankey_data = sankey_data[sankey_data[\"value\"] > 1]\n",
    "unique_vas_source = [x for x in sankey_data[\"source\"].unique()]\n",
    "unique_vas_tar = [x for x in sankey_data[\"target\"].unique()]\n",
    "unique_vars = list(set([*unique_vas_source, *unique_vas_tar]))\n",
    "unique_6 = [x[2:] for x in unique_vars if \"6\" in x]\n",
    "unique_5 = [x[2:] for x in unique_vars if \"5\" in x]\n",
    "unique_4 = [x[2:] for x in unique_vars if \"4\" in x]\n",
    "unique_3 = [x[2:] for x in unique_vars if \"3\" in x]\n",
    "unique_2 = [x[2:] for x in unique_vars if \"2\" in x]\n",
    "unique_3 = [\"PCB\"] + [x for x in unique_3 if x !=\"PCB\"]\n",
    "unique_2 = [\"IC\", \"PWB\"] + [x for x in unique_2 if x not in [\"IC\", \"PWB\"]]\n",
    "\n",
    "unique_5.reverse()\n",
    "\n",
    "for idx in sankey_data.index:\n",
    "    for i in [2, 3, 4, 5, 6]:\n",
    "        sankey_data.at[idx, \"source\"] = sankey_data.at[idx,\n",
    "                                                        \"source\"].replace(f\"{i}_\", \"\")\n",
    "        sankey_data.at[idx, \"target\"] = sankey_data.at[idx,\n",
    "                                                    \"target\"].replace(f\"{i}_\", \"\")\n",
    "\n",
    "nodes = {\n",
    "    'Pieces': ProcessGroup(unique_2, title='Pieces'),\n",
    "    'Parts': ProcessGroup(unique_3, title='Parts'),\n",
    "    'Devices': ProcessGroup(unique_4, title='Devices'),\n",
    "    'Systems': ProcessGroup(unique_5, title='Systems'),\n",
    "    'DC': ProcessGroup(unique_6, title='Data Center'),\n",
    "}\n",
    "\n",
    "ordering = [\n",
    "    ['Pieces'],\n",
    "    ['Parts'],\n",
    "    ['Devices'],\n",
    "    ['Systems'],\n",
    "    ['DC']        \n",
    "]\n",
    "\n",
    "bundles = [Bundle('Pieces', 'Devices'),\n",
    "           Bundle('Pieces', 'Parts'),\n",
    "           Bundle('Pieces', 'Systems'),\n",
    "           Bundle('Parts', 'Devices'),\n",
    "           Bundle('Parts', 'Systems'),\n",
    "           Bundle('Devices', 'Systems'),\n",
    "           Bundle('Systems', 'DC'),]\n",
    "           \n",
    "if True:\n",
    "    partition_2 = Partition.Simple(\"process\", unique_2)\n",
    "    partition_3 = Partition.Simple(\"process\", unique_3)\n",
    "    partition_4 = Partition.Simple(\"process\", unique_4)\n",
    "    partition_5 = Partition.Simple(\"process\", unique_5)\n",
    "    partition_6 = Partition.Simple(\"process\", unique_6)\n",
    "    nodes[\"Pieces\"].partition = partition_2\n",
    "    nodes[\"Parts\"].partition = partition_3\n",
    "    nodes[\"Devices\"].partition = partition_4\n",
    "    nodes[\"Systems\"].partition = partition_5\n",
    "    nodes[\"DC\"].partition = partition_6\n",
    "\n",
    "    sdd = SankeyDefinition(nodes, bundles, ordering)\n",
    "\n",
    "    class MyScale(QuantitativeScale):\n",
    "        def get_palette(self, link):\n",
    "            # Choose colour scheme based on link type (here, Employment Job)\n",
    "            name = \"YlGnBu_4\" #'PuBuGn_9'\n",
    "            return self.lookup_palette_name(name)\n",
    "\n",
    "        def get_color(self, link, value):\n",
    "            palette = self.get_palette(link)\n",
    "            return palette(0.2+ 0.8*value)\n",
    "\n",
    "    scale = MyScale('value', palette='Oranges_9')\n",
    "    f=40\n",
    "    w = int(25)*f\n",
    "    h = int(10)*f\n",
    "\n",
    "weave(sdd, sankey_data,link_color=scale).to_widget(width=w, height=h, margins=dict(left=120, right=100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey_data_rec=deepcopy(sankey_data)\n",
    "\n",
    "# the amount of \"recovered material\" is a product of the pcbs* gold content\n",
    "query = f'SELECT * FROM [6000LCAResults] WHERE ProductSystemID={ps}'\n",
    "lca = pd.read_sql_query(query, conn)\n",
    "\n",
    "lca[\"AssoID\"]=np.nan\n",
    "for idx in lca.index:\n",
    "    if lca.at[idx,\"Category\"].count(\":\")==2:\n",
    "        lca.at[idx,\"AssoID\"]=int(lca.at[idx,\"Category\"].split(\":\")[1])\n",
    "lca=lca[lca[\"AssoID\"]>3000]\n",
    "lca=lca[[\"AssoID\", \"Result\"]]\n",
    "list_3000 = list(lca[\"AssoID\"])\n",
    "lca.set_index(\"AssoID\", inplace=True)\n",
    "\n",
    "lca3000s = get_lca_contributions(list_3000,category=\"7122:Gold\",group=3000)\n",
    "#lca.drop(columns=[\"ID\",\"StandardDev\",\"DataQuality\"], inplace=True)\n",
    "lca3000s \n",
    "\n",
    "lca[\"UnitaryGoldContent\"]=np.nan\n",
    "lca[\"TotalGoldContent\"]=np.nan\n",
    "for idx in lca.index:\n",
    "    lca.at[idx,\"UnitaryGoldContent\"]=lca3000s.at[idx,\"Result\"]\n",
    "    lca.at[idx,\"TotalGoldContent\"]=lca.at[idx,\"Result\"]*lca3000s.at[idx,\"Result\"]\n",
    "total_PCB_GOLD = lca[\"TotalGoldContent\"].sum()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06746129116521746, 0.0673945445824077, 0.06328694283698635, 0.043414842786172636]\n"
     ]
    }
   ],
   "source": [
    "sankey_data = get_sankey_data_category(category=\"7122:Gold\")#\"EDIP-Gold\"))\n",
    "# Here I would prefer that the total \"NATURE INPUT\" is the total EDIP AMOUNT\n",
    "GOLD_FACTOR = 1.09006\n",
    "CRUSH_RATE = 0.7\n",
    "\"source\ttarget\tvalue\"\n",
    "#sankey_data[\"value\"] *= (1/total_impact)*100\n",
    "total_impact = 0\n",
    "\n",
    "for idx in sankey_data.index:\n",
    "    if sankey_data.at[idx,\"target\"][0:2]==\"6_\":\n",
    "        total_impact+=sankey_data.at[idx,\"value\"]\n",
    "        id_6 = sankey_data.at[idx,\"target\"]\n",
    "\n",
    "#make_new_flows \n",
    "## eol flows\n",
    "#A portion from the output is not in PCBs and not recovered\n",
    "not_in_pcb = total_impact-total_PCB_GOLD\n",
    "\n",
    "# 30 is lost to crushing\n",
    "crushing_waste = (1-CRUSH_RATE)*total_PCB_GOLD\n",
    "crushing_content =CRUSH_RATE*total_PCB_GOLD\n",
    "\n",
    "# pyrolysis has a 98% efficiency\n",
    "pyro_waste = 0.02*crushing_content\n",
    "pyro_recover= 0.98*crushing_content\n",
    "flow_waste_EOL = [id_6, \"Non Recovered\", not_in_pcb]\n",
    "flow_output_EOL = [id_6, \"EOL Treatment\", total_PCB_GOLD]\n",
    "\n",
    "flow_crushing_waste= [\"EOL Treatment\", \"Non Recovered\", crushing_waste]\n",
    "flow_crushing_content= [\"EOL Treatment\", \"Crushed_PCB\", crushing_content]\n",
    "flow_pyro_waste = [\"Crushed_PCB\", \"Non Recovered\", pyro_waste]\n",
    "flow_pyro_recover = [\"Crushed_PCB\", \"Recovered\", pyro_recover]\n",
    "for flow in [flow_waste_EOL, flow_output_EOL,flow_crushing_waste, flow_crushing_content,flow_pyro_waste,flow_pyro_recover]:\n",
    "    sankey_data.loc[len(sankey_data.index)]=flow\n",
    "\n",
    "flows_gold_2 = 0\n",
    "for idx in sankey_data.index:\n",
    "    if sankey_data.at[idx,\"source\"][0:2]==\"2_\":\n",
    "        flows_gold_2+=sankey_data.at[idx,\"value\"]\n",
    "\n",
    "total_gold_demand = flows_gold_2*1.02\n",
    "reduction_factor = 1-pyro_recover/total_gold_demand\n",
    "\n",
    "# Input from nature:\n",
    "for idx in sankey_data.index:\n",
    "    if sankey_data.at[idx,\"source\"][0:2]==\"2_\":\n",
    "        \n",
    "        new_flow = [\"1_Gold\", sankey_data.at[idx,\"source\"], sankey_data.at[idx,\"value\"]] \n",
    "        new_flow_metal_waste = [\"1_Gold\", \"Waste\", sankey_data.at[idx,\"value\"]*0.02] \n",
    "        new_flow_metal_prod = [\"0_Env\", \"1_Gold\", sankey_data.at[idx,\"value\"]*1.02*reduction_factor] \n",
    "        new_flow_metal_prod_waste = [\"0_Env\", \"Waste\", sankey_data.at[idx,\"value\"]*1.02*(GOLD_FACTOR-1)*reduction_factor] \n",
    "        sankey_data.loc[len(sankey_data.index)]=new_flow\n",
    "        sankey_data.loc[len(sankey_data.index)]=new_flow_metal_waste\n",
    "        sankey_data.loc[len(sankey_data.index)]=new_flow_metal_prod\n",
    "        sankey_data.loc[len(sankey_data.index)]=new_flow_metal_prod_waste\n",
    "\n",
    "\n",
    "\n",
    "unique_eol=[\"EOL Treatment\"]\n",
    "unique_crush=[\"Crushed_PCB\"]\n",
    "unique_pyro=[\"Recovered\"]\n",
    "unique_non_recov=[\"Non Recovered\"]\n",
    "\n",
    "sankey_data = sankey_data.groupby(['source', 'target']).sum().reset_index()\n",
    "\n",
    "sankey_data.loc[len(sankey_data.index)]=[\"From Recovery\", \"1_Gold\",pyro_recover]\n",
    "sankey_data.to_csv(\"Sankey_Recycling.csv\")\n",
    "print([total_impact, flows_gold_2,total_PCB_GOLD, pyro_recover])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Waste']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(total_impact)\n",
    "from copy import deepcopy\n",
    "sankey_data_a=deepcopy(sankey_data)\n",
    "sankey_data_a[\"value\"] *= (1/total_impact)*100\n",
    "sankey_data_a = sankey_data_a[sankey_data_a[\"value\"] > 1]\n",
    "\n",
    "unique_vas_source = [x for x in sankey_data_a[\"source\"].unique()]\n",
    "unique_vas_tar = [x for x in sankey_data_a[\"target\"].unique()]\n",
    "unique_vars = list(set([*unique_vas_source, *unique_vas_tar]))\n",
    "\n",
    "unique_6 = [x[2:] for x in unique_vars if \"6\" in x]\n",
    "unique_5 = [x[2:] for x in unique_vars if \"5\" in x]\n",
    "unique_4 = [x[2:] for x in unique_vars if \"4\" in x]\n",
    "unique_3 = [x[2:] for x in unique_vars if \"3\" in x]\n",
    "unique_2 = [x[2:] for x in unique_vars if \"2\" in x]\n",
    "unique_1 = [x[2:] for x in unique_vars if \"1\" in x] # Gold Metal\n",
    "unique_0 = [x[2:] for x in unique_vars if \"0\" in x] # Environment\n",
    "unique_waste = [\"Waste\"] # Waste\n",
    "unique_eol=[\"EOL Treatment\"]\n",
    "unique_crush=[\"Crushed_PCB\"]\n",
    "unique_pyro=[\"Recovered\"]\n",
    "unique_non_recov=[\"Non Recovered\"]\n",
    "unique_from_recov=[\"From Recovery\"]\n",
    "\n",
    "unique_5.reverse()\n",
    "print(unique_waste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cd94d82c234e78b895b3dee5be765e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SankeyWidget(groups=[{'id': '__Env_Waste_1', 'type': 'group', 'title': '', 'nodes': ['__Env_Waste_1^*']}, {'id…"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for idx in sankey_data_a.index:\n",
    "    for i in range(0, 9):\n",
    "        sankey_data_a.at[idx, \"source\"] = sankey_data_a.at[idx,\n",
    "                                                           \"source\"].replace(f\"{i}_\", \"\")\n",
    "        sankey_data_a.at[idx, \"target\"] = sankey_data_a.at[idx,\n",
    "                                                           \"target\"].replace(f\"{i}_\", \"\")\n",
    "\n",
    "nodes = {\n",
    "    \"Env\": ProcessGroup(unique_0, title='Env.'),\n",
    "    \"FromR\": ProcessGroup(unique_from_recov, title='Recov.'),\n",
    "    \"Metal\": ProcessGroup(unique_1, title='Metal'),\n",
    "    \"Waste\": ProcessGroup(unique_waste, title='Waste'),\n",
    "    'Pieces': ProcessGroup(unique_2, title='Pieces'),\n",
    "    'Parts': ProcessGroup(unique_3, title='Parts'),\n",
    "    'Devices': ProcessGroup(unique_4, title='Devices'),\n",
    "    'Systems': ProcessGroup(unique_5, title='Systems'),\n",
    "    'DC': ProcessGroup(unique_6, title='Data Center'),\n",
    "    \"EOL\": ProcessGroup(unique_eol, title='EOL'),\n",
    "    \"Treatment\": ProcessGroup(unique_crush, title='Treatment'),\n",
    "    \"Recycling\": ProcessGroup(unique_pyro, title='Recovered'),\n",
    "    \"NonRec\": ProcessGroup(unique_non_recov, title='NonRecov'),\n",
    "\n",
    "}\n",
    "\n",
    "ordering = [\n",
    "    [[], [\"Env\", \"FromR\"]],\n",
    "    [[], [\"Metal\"]],\n",
    "    [[\"Waste\"], ['Pieces']],\n",
    "    [[], ['Parts']],\n",
    "    [[], ['Devices']],\n",
    "    [[], ['Systems']],\n",
    "    [[], ['DC']],\n",
    "    [[], ['EOL']],\n",
    "    [[], ['Treatment']],\n",
    "    [[\"NonRec\"], ['Recycling']],\n",
    "\n",
    "]\n",
    "\n",
    "bundles = [\n",
    "    Bundle('Env', 'Metal'),\n",
    "    Bundle('FromR', 'Metal'),\n",
    "\n",
    "    Bundle('Env', 'Waste'),\n",
    "    Bundle('Metal', 'Pieces'),\n",
    "    Bundle('Metal', 'Waste'),\n",
    "\n",
    "    Bundle('Pieces', 'Devices'),\n",
    "    Bundle('Pieces', 'Parts'),\n",
    "    Bundle('Pieces', 'Systems'),\n",
    "    Bundle('Parts', 'Devices'),\n",
    "    Bundle('Parts', 'Systems'),\n",
    "    Bundle('Devices', 'Systems'),\n",
    "    Bundle('Systems', 'DC'),\n",
    "    Bundle('DC', 'EOL'),\n",
    "    Bundle('EOL', 'Treatment'),\n",
    "    Bundle('Treatment', \"Recycling\"),\n",
    "    Bundle('DC', 'NonRec'),\n",
    "    Bundle('EOL', 'NonRec'),\n",
    "    Bundle('Treatment', \"NonRec\"),]\n",
    "\n",
    "#sankey_data[\"value\"] *= (1/total_impact)*100\n",
    "\n",
    "partition_2 = Partition.Simple(\"process\", unique_2)\n",
    "partition_3 = Partition.Simple(\"process\", unique_3)\n",
    "partition_4 = Partition.Simple(\"process\", unique_4)\n",
    "partition_5 = Partition.Simple(\"process\", unique_5)\n",
    "partition_6 = Partition.Simple(\"process\", unique_6)\n",
    "nodes[\"Pieces\"].partition = partition_2\n",
    "nodes[\"Parts\"].partition = partition_3\n",
    "nodes[\"Devices\"].partition = partition_4\n",
    "nodes[\"Systems\"].partition = partition_5\n",
    "nodes[\"DC\"].partition = partition_6\n",
    "\n",
    "sdd = SankeyDefinition(nodes, bundles, ordering)\n",
    "\n",
    "\n",
    "class MyScale(QuantitativeScale):\n",
    "    def get_palette(self, link):\n",
    "        # Choose colour scheme based on link type (here, Employment Job)\n",
    "        name = 'YlGnBu_4'\n",
    "        return self.lookup_palette_name(name)\n",
    "\n",
    "    def get_color(self, link, value):\n",
    "        palette = self.get_palette(link)\n",
    "        return palette(0.1 + 0.9*value)\n",
    "\n",
    "\n",
    "scale = MyScale('value', palette='YlGnBu_5')\n",
    "f = 40\n",
    "w = int(42)*f\n",
    "h = int(14)*f\n",
    "\n",
    "weave(sdd, sankey_data_a, link_color=scale).to_widget(\n",
    "    width=w, height=h, margins=dict(left=60, right=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "flows = pd.read_csv(StringIO(\"\"\"\n",
    "source,target,type,value\n",
    "a,b,main,1.5\n",
    "a,c,main,1\n",
    "b,d,main,2\n",
    "c,d,main,1\n",
    "d,e,main,0.5\n",
    "d,o, main,2.5\n",
    "e,b,back,0.5\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b489cc11d44ababb7a844ca4ad3644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SankeyWidget(groups=[{'id': '__e_b_1', 'type': 'group', 'title': '', 'nodes': ['__e_b_1^*']}, {'id': '__e_b_2'…"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from floweaver import *\n",
    "\n",
    "# Set the default size to fit the documentation better.\n",
    "size = dict(width=570, height=300)\n",
    "\n",
    "nodes = {\n",
    "    'a': ProcessGroup(['a']),\n",
    "    'b': ProcessGroup(['b']),\n",
    "    'c': ProcessGroup(['c']),\n",
    "    'd': ProcessGroup(['d']),\n",
    "    'e': ProcessGroup(['e']),\n",
    "    'o': ProcessGroup(['o']),\n",
    "    'back': Waypoint(direction='L'),\n",
    "}\n",
    "\n",
    "bundles = [\n",
    "    Bundle('e', 'b'),\n",
    "    Bundle('a', 'b'),\n",
    "    Bundle('a', 'c'),\n",
    "    Bundle('b', 'd'),\n",
    "    Bundle('c', 'd'),\n",
    "    Bundle('d', 'e'),\n",
    "    Bundle('d', 'o'),\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "ordering = [\n",
    "    [['a'],[]],\n",
    "    [[ 'c',\"b\"],[\"back\"]],\n",
    "    [ ['d'],[]],\n",
    "        [[\"o\"],[\"e\"]],\n",
    "]\n",
    "\n",
    "sdd = SankeyDefinition(nodes, bundles, ordering)\n",
    "\n",
    "weave(sdd, flows).to_widget(**size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13c2a60ebe0c1ea69d047832008d6b0505217a869a65024dc87d3047ecd0fc38"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dataEval')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
